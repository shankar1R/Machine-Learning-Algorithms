{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "img = cv.imread(\"C:/Users/User/Pictures/Screenshot (58).png\")\n",
    "\n",
    "cv.imshow(\"Display window\", img)\n",
    "k = cv.waitKey(0) # Wait for a keystroke in the window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install the pyqrcode pakage for vscode\n",
    "# pip install Keras\n",
    "# pip install tensorFlow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 23s 76ms/step - loss: 0.4819 - accuracy: 0.8455 - val_loss: 0.0861 - val_accuracy: 0.9740\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 23s 77ms/step - loss: 0.1568 - accuracy: 0.9532 - val_loss: 0.0528 - val_accuracy: 0.9815\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 23s 77ms/step - loss: 0.1194 - accuracy: 0.9637 - val_loss: 0.0434 - val_accuracy: 0.9853\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 23s 77ms/step - loss: 0.0970 - accuracy: 0.9709 - val_loss: 0.0352 - val_accuracy: 0.9878\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 22s 73ms/step - loss: 0.0871 - accuracy: 0.9734 - val_loss: 0.0342 - val_accuracy: 0.9887\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#1 prelabeled Datasets\n",
    "# import the keras pakage\n",
    "from  keras.datasets import mnist \n",
    "\n",
    "\n",
    "#2. Numerous implemented layers and parameters\n",
    "\n",
    "# import th eanother pakage\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "import numpy as np\n",
    "\n",
    "# 3. Multiple methods for Data Preprocessing\n",
    "# divide the  Data into (X_train ,Y_train,X_test,Y_test)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape in form of (60000, 28, 28, 1)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1).astype('float32')\n",
    "#normalize to get data in range of 0-1\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "number_of_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "y_test = np_utils.to_categorical(y_test, number_of_classes)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(number_of_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=200)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"E:\\Machine Learning Algorithms\\opencv\\grayscale_image.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "# resize image\n",
    "resized = cv2.resize(img, (28,28), interpolation = cv2.INTER_AREA)\n",
    "img = np.resize(resized, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)\n",
    "y_pred = model.predict(im2arr)\n",
    "predicted_digit=np.argmax(y_pred)\n",
    "print(y_pred)\n",
    "print(predicted_digit)\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"C:/Users/User/Pictures/10 img.jfif\", cv2.IMREAD_GRAYSCALE)\n",
    "# resize image\n",
    "resized = cv2.resize(img, (28,28), interpolation = cv2.INTER_AREA)\n",
    "img = np.resize(resized, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)\n",
    "y_pred = model.predict(im2arr)\n",
    "predicted_digit=np.argmax(y_pred)\n",
    "print(y_pred)\n",
    "print(predicted_digit)\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Example categorical labels\n",
    "labels = ['cat', 'dog', 'bird', 'dog', 'cat']\n",
    "\n",
    "# Create a dictionary to map unique label strings to numerical values\n",
    "label_map = {label: idx for idx, label in enumerate(set(labels))}\n",
    "\n",
    "# Convert string labels to numerical categorical labels\n",
    "numerical_labels = [label_map[label] for label in labels]\n",
    "\n",
    "# Perform one-hot encoding\n",
    "encoded_labels = to_categorical(numerical_labels)\n",
    "\n",
    "print(encoded_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras with Timeseries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "99/99 [==============================] - 1s 958us/step - loss: 0.3952\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.1940\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0519\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0232\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0228\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0223\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0222\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0227\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0225\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0224\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0224\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0225\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0227\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0225\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0230\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0227\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0225\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0226\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0225\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0226\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0225\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0228\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0229\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0229\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0225\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 0s 987us/step - loss: 0.0224\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0224\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0232\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0230\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0225\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0227\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 0s 946us/step - loss: 0.0221\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0229\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0232\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0227\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0225\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0228\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0228\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0228\n",
      "Epoch 40/100\n",
      "99/99 [==============================] - 0s 946us/step - loss: 0.0225\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0229\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0226\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 0s 936us/step - loss: 0.0222\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0227\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 0s 977us/step - loss: 0.0226\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0225\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 0s 845us/step - loss: 0.0226\n",
      "Epoch 49/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0232\n",
      "Epoch 50/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0232\n",
      "Epoch 51/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0226\n",
      "Epoch 52/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0222\n",
      "Epoch 53/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0224\n",
      "Epoch 54/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0225\n",
      "Epoch 55/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0228\n",
      "Epoch 56/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0226\n",
      "Epoch 57/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0226\n",
      "Epoch 58/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0223\n",
      "Epoch 59/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0225\n",
      "Epoch 60/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0227\n",
      "Epoch 61/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0228\n",
      "Epoch 62/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0229\n",
      "Epoch 63/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0222\n",
      "Epoch 64/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0227\n",
      "Epoch 65/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0225\n",
      "Epoch 66/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0232\n",
      "Epoch 67/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0227\n",
      "Epoch 68/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0226\n",
      "Epoch 69/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0229\n",
      "Epoch 70/100\n",
      "99/99 [==============================] - 0s 936us/step - loss: 0.0222\n",
      "Epoch 71/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0228\n",
      "Epoch 72/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0225\n",
      "Epoch 73/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0223\n",
      "Epoch 74/100\n",
      "99/99 [==============================] - 0s 977us/step - loss: 0.0233\n",
      "Epoch 75/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Epoch 76/100\n",
      "99/99 [==============================] - 0s 845us/step - loss: 0.0229\n",
      "Epoch 77/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0220\n",
      "Epoch 78/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0228\n",
      "Epoch 79/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0222\n",
      "Epoch 80/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0229\n",
      "Epoch 81/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0224\n",
      "Epoch 82/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0224\n",
      "Epoch 83/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Epoch 84/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0227\n",
      "Epoch 85/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0223\n",
      "Epoch 86/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0223\n",
      "Epoch 87/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0223\n",
      "Epoch 88/100\n",
      "99/99 [==============================] - 0s 878us/step - loss: 0.0226\n",
      "Epoch 89/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Epoch 90/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Epoch 91/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0226\n",
      "Epoch 92/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0224\n",
      "Epoch 93/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0221\n",
      "Epoch 94/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0223\n",
      "Epoch 95/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0224\n",
      "Epoch 96/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0222\n",
      "Epoch 97/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0225\n",
      "Epoch 98/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0223\n",
      "Epoch 99/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0224\n",
      "Epoch 100/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x277cf06f0d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Generate synthetic timeseries data\n",
    "def generate_timeseries_data(n_steps):\n",
    "    time = np.linspace(0, 2*np.pi, n_steps)\n",
    "    data = np.sin(time) + np.random.normal(0, 0.1, n_steps)\n",
    "    return data\n",
    "\n",
    "n_steps = 100\n",
    "data = generate_timeseries_data(n_steps)\n",
    "\n",
    "# Prepare data for LSTM (input and target)\n",
    "X = data[:-1]\n",
    "y = data[1:]\n",
    "\n",
    "\n",
    "# Reshape data for LSTM (samples, timesteps, features)\n",
    "X = X.reshape(-1, 1, 1)\n",
    "\n",
    "# Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(1, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, batch_size=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data, defining Training models and predict results in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 48ms/step - loss: 1.9048 - accuracy: 0.3519 - val_loss: 2.1018 - val_accuracy: 0.1667\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.8257 - accuracy: 0.3519 - val_loss: 2.0055 - val_accuracy: 0.1667\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7546 - accuracy: 0.3519 - val_loss: 1.9096 - val_accuracy: 0.1667\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6845 - accuracy: 0.3519 - val_loss: 1.8157 - val_accuracy: 0.1667\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.6241 - accuracy: 0.3519 - val_loss: 1.7241 - val_accuracy: 0.1667\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.5568 - accuracy: 0.3519 - val_loss: 1.6423 - val_accuracy: 0.1667\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.4995 - accuracy: 0.3519 - val_loss: 1.5686 - val_accuracy: 0.1667\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.4466 - accuracy: 0.3519 - val_loss: 1.4993 - val_accuracy: 0.1667\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.3990 - accuracy: 0.3519 - val_loss: 1.4365 - val_accuracy: 0.1667\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3563 - accuracy: 0.3333 - val_loss: 1.3792 - val_accuracy: 0.1667\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3157 - accuracy: 0.2963 - val_loss: 1.3281 - val_accuracy: 0.1667\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.2803 - accuracy: 0.2130 - val_loss: 1.2832 - val_accuracy: 0.1667\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.2485 - accuracy: 0.1296 - val_loss: 1.2447 - val_accuracy: 0.2500\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2201 - accuracy: 0.1111 - val_loss: 1.2109 - val_accuracy: 0.1667\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.1952 - accuracy: 0.2130 - val_loss: 1.1822 - val_accuracy: 0.3333\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.1716 - accuracy: 0.2963 - val_loss: 1.1577 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.1489 - accuracy: 0.3241 - val_loss: 1.1341 - val_accuracy: 0.4167\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.1275 - accuracy: 0.3241 - val_loss: 1.1130 - val_accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.1076 - accuracy: 0.3519 - val_loss: 1.0932 - val_accuracy: 0.5000\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0882 - accuracy: 0.4352 - val_loss: 1.0741 - val_accuracy: 0.5000\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0695 - accuracy: 0.4722 - val_loss: 1.0555 - val_accuracy: 0.5833\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0522 - accuracy: 0.4630 - val_loss: 1.0383 - val_accuracy: 0.5000\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0349 - accuracy: 0.4444 - val_loss: 1.0213 - val_accuracy: 0.5000\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0180 - accuracy: 0.4630 - val_loss: 1.0052 - val_accuracy: 0.4167\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0025 - accuracy: 0.4722 - val_loss: 0.9906 - val_accuracy: 0.5833\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9866 - accuracy: 0.5000 - val_loss: 0.9757 - val_accuracy: 0.5833\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.9696 - accuracy: 0.5370 - val_loss: 0.9599 - val_accuracy: 0.5833\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9521 - accuracy: 0.5463 - val_loss: 0.9429 - val_accuracy: 0.5833\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9352 - accuracy: 0.5833 - val_loss: 0.9269 - val_accuracy: 0.6667\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9159 - accuracy: 0.6296 - val_loss: 0.9088 - val_accuracy: 0.6667\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8970 - accuracy: 0.6204 - val_loss: 0.8918 - val_accuracy: 0.6667\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8768 - accuracy: 0.6574 - val_loss: 0.8745 - val_accuracy: 0.5833\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8591 - accuracy: 0.6667 - val_loss: 0.8609 - val_accuracy: 0.5833\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8431 - accuracy: 0.6667 - val_loss: 0.8520 - val_accuracy: 0.5833\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8283 - accuracy: 0.6667 - val_loss: 0.8425 - val_accuracy: 0.5833\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8149 - accuracy: 0.6667 - val_loss: 0.8326 - val_accuracy: 0.5833\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8020 - accuracy: 0.6667 - val_loss: 0.8239 - val_accuracy: 0.5833\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7905 - accuracy: 0.6759 - val_loss: 0.8154 - val_accuracy: 0.5833\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7787 - accuracy: 0.6852 - val_loss: 0.8074 - val_accuracy: 0.8333\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7678 - accuracy: 0.7315 - val_loss: 0.7996 - val_accuracy: 0.9167\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7576 - accuracy: 0.7870 - val_loss: 0.7912 - val_accuracy: 0.9167\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7474 - accuracy: 0.8056 - val_loss: 0.7823 - val_accuracy: 0.9167\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7379 - accuracy: 0.8056 - val_loss: 0.7746 - val_accuracy: 0.9167\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7285 - accuracy: 0.8241 - val_loss: 0.7668 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7194 - accuracy: 0.8519 - val_loss: 0.7595 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7105 - accuracy: 0.8611 - val_loss: 0.7520 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7021 - accuracy: 0.8796 - val_loss: 0.7450 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6939 - accuracy: 0.8981 - val_loss: 0.7386 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6858 - accuracy: 0.9167 - val_loss: 0.7319 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6782 - accuracy: 0.9259 - val_loss: 0.7262 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6867 - accuracy: 0.8667\n",
      "Test Loss: 0.6867239475250244\n",
      "Test Accuracy: 0.8666666746139526\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "Predicted Classes: ['setosa', 'versicolor', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Create the MLP model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = [[5.1, 3.5, 1.4, 0.2], [6.4, 3.2, 4.5, 1.5], [7.3, 2.9, 6.3, 1.8]]\n",
    "\n",
    "\n",
    "predictions = model.predict(new_data)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_classes = [iris.target_names[pred.argmax()] for pred in predictions]\n",
    "print(\"Predicted Classes:\", predicted_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras with Support Vector Machine(SVM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 1.0\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.3333 - accuracy: 0.3000\n",
      "SVM-like model accuracy: 0.30000001192092896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the SVM model using SVC from scikit-learn\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "accuracy = svm_model.score(X_test, y_test)\n",
    "print(\"SVM accuracy:\", accuracy)\n",
    "\n",
    "# Alternatively, you can use Keras to build an SVM-like model\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=4, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='hinge', metrics=['accuracy'])\n",
    "\n",
    "# Train the SVM-like model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# Evaluate the SVM-like model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"SVM-like model accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras with reinforcement learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8384\\2444255991.py:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  action = np.argmax(q_table[state, :])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8384\\2444255991.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# Train Q-learning agent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mq_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq_learning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# Test the agent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8384\\2444255991.py\u001b[0m in \u001b[0;36mq_learning\u001b[1;34m(env, episodes, alpha, gamma, epsilon)\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Create the CartPole environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Q-learning algorithm\n",
    "def q_learning(env, episodes=1000, alpha=0.1, gamma=0.99, epsilon=0.1):\n",
    "    n_actions = env.action_space.n\n",
    "    n_states = env.observation_space.shape[0]\n",
    "    q_table = np.zeros((n_states, n_actions))\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            if float (np.random.rand()) < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q_table[state, :])\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            q_next = np.max(q_table[next_state, :])\n",
    "            q_table[state, action] = (1 - alpha) * q_table[state, action] + alpha * (reward + gamma * q_next)\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "    return q_table\n",
    "\n",
    "# Train Q-learning agent\n",
    "q_table = q_learning(env)\n",
    "\n",
    "# Test the agent\n",
    "state = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = np.argmax(q_table[state, :])\n",
    "    next_state, _, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    state = next_state\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# N=np.random.rand()\n",
    "# N \n",
    "\n",
    "N=int(input(\"enter the number\"))\n",
    "\n",
    "print(float(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "99/99 [==============================] - 1s 1ms/step - loss: 0.4214\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 0s 987us/step - loss: 0.2160\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 0s 997us/step - loss: 0.0636\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0276\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 0s 967us/step - loss: 0.0269\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 0s 967us/step - loss: 0.0269\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 0s 987us/step - loss: 0.0277\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 0s 977us/step - loss: 0.0270\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0271\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0267\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 0s 967us/step - loss: 0.0266\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 0s 967us/step - loss: 0.0269\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0265\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0265\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0269\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 0s 946us/step - loss: 0.0265\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0269\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 0s 987us/step - loss: 0.0267\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 0s 946us/step - loss: 0.0265\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 0s 997us/step - loss: 0.0267\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 0s 987us/step - loss: 0.0268\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 0s 997us/step - loss: 0.0267\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0269\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0268\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0273\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0269\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 0s 997us/step - loss: 0.0268\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0264\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0270\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0267\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0262\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0269\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0267\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0271\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0268\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0263\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0273\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0267\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0268\n",
      "Epoch 40/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0264\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0272\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0268\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0275\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0263\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 0s 967us/step - loss: 0.0272\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0268\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0268\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0267\n",
      "Epoch 49/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0268\n",
      "Epoch 50/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0269\n",
      "Epoch 51/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0265\n",
      "Epoch 52/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0268\n",
      "Epoch 53/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0271\n",
      "Epoch 54/100\n",
      "99/99 [==============================] - 0s 946us/step - loss: 0.0268\n",
      "Epoch 55/100\n",
      "99/99 [==============================] - 0s 946us/step - loss: 0.0267\n",
      "Epoch 56/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0267\n",
      "Epoch 57/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0266\n",
      "Epoch 58/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0264\n",
      "Epoch 59/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0270\n",
      "Epoch 60/100\n",
      "99/99 [==============================] - 0s 936us/step - loss: 0.0271\n",
      "Epoch 61/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0267\n",
      "Epoch 62/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0267\n",
      "Epoch 63/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0271\n",
      "Epoch 64/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0264\n",
      "Epoch 65/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0267\n",
      "Epoch 66/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0273\n",
      "Epoch 67/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0267\n",
      "Epoch 68/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0266\n",
      "Epoch 69/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0266\n",
      "Epoch 70/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0265\n",
      "Epoch 71/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0271\n",
      "Epoch 72/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0269\n",
      "Epoch 73/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0269\n",
      "Epoch 74/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0266\n",
      "Epoch 75/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0269\n",
      "Epoch 76/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0264\n",
      "Epoch 77/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0270\n",
      "Epoch 78/100\n",
      "99/99 [==============================] - 0s 946us/step - loss: 0.0269\n",
      "Epoch 79/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0266\n",
      "Epoch 80/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0269\n",
      "Epoch 81/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0268\n",
      "Epoch 82/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0261\n",
      "Epoch 83/100\n",
      "99/99 [==============================] - 0s 946us/step - loss: 0.0273\n",
      "Epoch 84/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0267\n",
      "Epoch 85/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0267\n",
      "Epoch 86/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0261\n",
      "Epoch 87/100\n",
      "99/99 [==============================] - 0s 987us/step - loss: 0.0272\n",
      "Epoch 88/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0264\n",
      "Epoch 89/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0264\n",
      "Epoch 90/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0265\n",
      "Epoch 91/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0267\n",
      "Epoch 92/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0266\n",
      "Epoch 93/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0267\n",
      "Epoch 94/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0267\n",
      "Epoch 95/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0268\n",
      "Epoch 96/100\n",
      "99/99 [==============================] - 0s 936us/step - loss: 0.0268\n",
      "Epoch 97/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0265\n",
      "Epoch 98/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0269\n",
      "Epoch 99/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0264\n",
      "Epoch 100/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x277d2be6940>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Generate synthetic timeseries data\n",
    "def generate_timeseries_data(n_steps):\n",
    "    time = np.linspace(0, 2*np.pi, n_steps)\n",
    "    data = np.sin(time) + np.random.normal(0, 0.1, n_steps)\n",
    "    return data\n",
    "\n",
    "n_steps = 100\n",
    "data = generate_timeseries_data(n_steps)\n",
    "\n",
    "# Prepare data for LSTM (input and target)\n",
    "X = data[:-1]\n",
    "y = data[1:]\n",
    "\n",
    "# Reshape data for LSTM (samples, timesteps, features)\n",
    "X = X.reshape(-1, 1, 1)\n",
    "\n",
    "# Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(1, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, batch_size=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# Example categorical labels\n",
    "labels = ['cat', 'dog', 'bird', 'dog', 'cat']\n",
    "# Perform one-hot encoding\n",
    "encoded_labels = to_categorical(labels)\n",
    "print(encoded_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'dict' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'dict' and 'dict'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19176\\3275624622.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m# Train Q-learning agent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[0mq_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq_learning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;31m# Test the agent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19176\\3275624622.py\u001b[0m in \u001b[0;36mq_learning\u001b[1;34m(env, episodes, alpha, gamma, epsilon)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscretize_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Convert the state to a tuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19176\\3275624622.py\u001b[0m in \u001b[0;36mdiscretize_state\u001b[1;34m(state, n_buckets, state_bounds)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mn_bins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_buckets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mdiscretized_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlower_bound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupper_bound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_bins\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mdiscretized_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdigitize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscretized_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscretized_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mdigitize\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mdigitize\u001b[1;34m(x, bins, right)\u001b[0m\n\u001b[0;32m   5557\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mside\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mside\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5558\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5559\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mside\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mside\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36msearchsorted\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msearchsorted\u001b[1;34m(a, v, side, sorter)\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m     \"\"\"\n\u001b[1;32m-> 1387\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'searchsorted'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mside\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mside\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msorter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;31m# Call _wrapit from within the except clause to ensure a potential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;31m# exception has a traceback chain.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'dict' and 'dict'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Create the CartPole environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Function to discretize the continuous state space\n",
    "def discretize_state(state, n_buckets=(1, 1, 6, 12), state_bounds=None):\n",
    "    if state_bounds is None:\n",
    "        state_bounds = list(zip(env.observation_space.low, env.observation_space.high))\n",
    "        state_bounds[1] = [-0.5, 0.5]\n",
    "        state_bounds[3] = [-math.radians(50), math.radians(50)]\n",
    "\n",
    "    discretized_state = []\n",
    "    for i in range(len(state)):\n",
    "        value = state[i]\n",
    "        lower_bound, upper_bound = state_bounds[i]\n",
    "        n_bins = n_buckets[i]\n",
    "        discretized_value = np.linspace(lower_bound, upper_bound, n_bins + 1)[1:-1]\n",
    "        discretized_state.append(np.digitize(value, discretized_value))\n",
    "    return tuple(discretized_state)\n",
    "\n",
    "# Q-learning algorithm\n",
    "def q_learning(env, episodes=2000, alpha=0.1, gamma=0.99, epsilon=0.1):\n",
    "    n_actions = env.action_space.n\n",
    "    n_states = tuple((x + 1 for x in [1, 1, 6, 12]))  # Add 1 to each dimension to account for discretization\n",
    "\n",
    "    q_table = np.zeros(n_states + (n_actions,))\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        state = discretize_state(state)  # Convert the state to a tuple\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q_table[state])\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = discretize_state(next_state)\n",
    "\n",
    "            q_next = np.max(q_table[next_state])\n",
    "            q_table[state][action] = (1 - alpha) * q_table[state][action] + alpha * (reward + gamma * q_next)\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "    return q_table\n",
    "\n",
    "# Train Q-learning agent\n",
    "q_table = q_learning(env)\n",
    "\n",
    "# Test the agent\n",
    "state = env.reset()\n",
    "state = discretize_state(state)\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = np.argmax(q_table[state])\n",
    "    next_state, _, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    state = discretize_state(next_state)\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
