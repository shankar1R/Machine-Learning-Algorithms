{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install the pyqrcode pakage for vscode\n",
    "# pip install Keras\n",
    "# pip install tensorFlow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 24s 77ms/step - loss: 0.4774 - accuracy: 0.8474 - val_loss: 0.0802 - val_accuracy: 0.9748\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 23s 77ms/step - loss: 0.1528 - accuracy: 0.9543 - val_loss: 0.0509 - val_accuracy: 0.9833\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 23s 77ms/step - loss: 0.1170 - accuracy: 0.9648 - val_loss: 0.0393 - val_accuracy: 0.9872\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 23s 77ms/step - loss: 0.0985 - accuracy: 0.9701 - val_loss: 0.0368 - val_accuracy: 0.9885\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 24s 79ms/step - loss: 0.0858 - accuracy: 0.9735 - val_loss: 0.0333 - val_accuracy: 0.9896\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Predicted Digit: 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import cv2\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1).astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "number_of_classes = 10\n",
    "y_train = to_categorical(y_train, number_of_classes)\n",
    "y_test = to_categorical(y_test, number_of_classes)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(number_of_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=200)\n",
    "\n",
    "# Load and preprocess the test image\n",
    "img = cv2.imread('C:/Users/User/Downloads/10 img (1).png', cv2.IMREAD_GRAYSCALE)\n",
    "resized = cv2.resize(img, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "img = np.resize(resized, (28, 28, 1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1, 28, 28, 1)\n",
    "\n",
    "# Make predictions and get the digit output\n",
    "y_pred = model.predict(im2arr)\n",
    "digit = np.argmax(y_pred)\n",
    "\n",
    "print(\"Predicted Digit:\", digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"C:/Users/User/Pictures/10 img.jfif\", cv2.IMREAD_GRAYSCALE)\n",
    "# resize image\n",
    "resized = cv2.resize(img, (28,28), interpolation = cv2.INTER_AREA)\n",
    "img = np.resize(resized, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)\n",
    "y_pred = model.predict(im2arr)\n",
    "predicted_digit=np.argmax(y_pred)\n",
    "print(y_pred)\n",
    "print(predicted_digit)\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Example categorical labels\n",
    "labels = ['cat', 'dog', 'bird', 'dog', 'cat']\n",
    "\n",
    "# Create a dictionary to map unique label strings to numerical values\n",
    "label_map = {label: idx for idx, label in enumerate(set(labels))}\n",
    "\n",
    "# Convert string labels to numerical categorical labels\n",
    "numerical_labels = [label_map[label] for label in labels]\n",
    "\n",
    "# Perform one-hot encoding\n",
    "encoded_labels = to_categorical(numerical_labels)\n",
    "\n",
    "print(encoded_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras with Timeseries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "99/99 [==============================] - 1s 958us/step - loss: 0.3952\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.1940\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0519\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0232\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0228\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0223\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0222\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0227\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0225\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0224\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0224\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0225\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0227\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0225\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0230\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0227\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0225\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0226\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0225\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0226\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0225\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0228\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0229\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0229\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0225\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 0s 987us/step - loss: 0.0224\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0224\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0232\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0230\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0225\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0227\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 0s 946us/step - loss: 0.0221\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0229\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0232\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0227\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0225\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0228\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0228\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0228\n",
      "Epoch 40/100\n",
      "99/99 [==============================] - 0s 946us/step - loss: 0.0225\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0229\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0226\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 0s 936us/step - loss: 0.0222\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0227\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 0s 977us/step - loss: 0.0226\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0225\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 0s 845us/step - loss: 0.0226\n",
      "Epoch 49/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0232\n",
      "Epoch 50/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0232\n",
      "Epoch 51/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0226\n",
      "Epoch 52/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0222\n",
      "Epoch 53/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0224\n",
      "Epoch 54/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0225\n",
      "Epoch 55/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0228\n",
      "Epoch 56/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0226\n",
      "Epoch 57/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0226\n",
      "Epoch 58/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0223\n",
      "Epoch 59/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0225\n",
      "Epoch 60/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0227\n",
      "Epoch 61/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0228\n",
      "Epoch 62/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0229\n",
      "Epoch 63/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0222\n",
      "Epoch 64/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0227\n",
      "Epoch 65/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0225\n",
      "Epoch 66/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0232\n",
      "Epoch 67/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0227\n",
      "Epoch 68/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0226\n",
      "Epoch 69/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0229\n",
      "Epoch 70/100\n",
      "99/99 [==============================] - 0s 936us/step - loss: 0.0222\n",
      "Epoch 71/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0228\n",
      "Epoch 72/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0225\n",
      "Epoch 73/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0223\n",
      "Epoch 74/100\n",
      "99/99 [==============================] - 0s 977us/step - loss: 0.0233\n",
      "Epoch 75/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Epoch 76/100\n",
      "99/99 [==============================] - 0s 845us/step - loss: 0.0229\n",
      "Epoch 77/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0220\n",
      "Epoch 78/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0228\n",
      "Epoch 79/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0222\n",
      "Epoch 80/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0229\n",
      "Epoch 81/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0224\n",
      "Epoch 82/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0224\n",
      "Epoch 83/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Epoch 84/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0227\n",
      "Epoch 85/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0223\n",
      "Epoch 86/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0223\n",
      "Epoch 87/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0223\n",
      "Epoch 88/100\n",
      "99/99 [==============================] - 0s 878us/step - loss: 0.0226\n",
      "Epoch 89/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Epoch 90/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Epoch 91/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0226\n",
      "Epoch 92/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0224\n",
      "Epoch 93/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0221\n",
      "Epoch 94/100\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.0223\n",
      "Epoch 95/100\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.0224\n",
      "Epoch 96/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0222\n",
      "Epoch 97/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0225\n",
      "Epoch 98/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0223\n",
      "Epoch 99/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0224\n",
      "Epoch 100/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x277cf06f0d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Generate synthetic timeseries data\n",
    "def generate_timeseries_data(n_steps):\n",
    "    time = np.linspace(0, 2*np.pi, n_steps)\n",
    "    data = np.sin(time) + np.random.normal(0, 0.1, n_steps)\n",
    "    return data\n",
    "\n",
    "n_steps = 100\n",
    "data = generate_timeseries_data(n_steps)\n",
    "\n",
    "# Prepare data for LSTM (input and target)\n",
    "X = data[:-1]\n",
    "y = data[1:]\n",
    "\n",
    "\n",
    "# Reshape data for LSTM (samples, timesteps, features)\n",
    "X = X.reshape(-1, 1, 1)\n",
    "\n",
    "# Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(1, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, batch_size=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data, defining Training models and predict results in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 48ms/step - loss: 1.9048 - accuracy: 0.3519 - val_loss: 2.1018 - val_accuracy: 0.1667\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.8257 - accuracy: 0.3519 - val_loss: 2.0055 - val_accuracy: 0.1667\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7546 - accuracy: 0.3519 - val_loss: 1.9096 - val_accuracy: 0.1667\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6845 - accuracy: 0.3519 - val_loss: 1.8157 - val_accuracy: 0.1667\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.6241 - accuracy: 0.3519 - val_loss: 1.7241 - val_accuracy: 0.1667\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.5568 - accuracy: 0.3519 - val_loss: 1.6423 - val_accuracy: 0.1667\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.4995 - accuracy: 0.3519 - val_loss: 1.5686 - val_accuracy: 0.1667\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.4466 - accuracy: 0.3519 - val_loss: 1.4993 - val_accuracy: 0.1667\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.3990 - accuracy: 0.3519 - val_loss: 1.4365 - val_accuracy: 0.1667\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3563 - accuracy: 0.3333 - val_loss: 1.3792 - val_accuracy: 0.1667\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3157 - accuracy: 0.2963 - val_loss: 1.3281 - val_accuracy: 0.1667\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.2803 - accuracy: 0.2130 - val_loss: 1.2832 - val_accuracy: 0.1667\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.2485 - accuracy: 0.1296 - val_loss: 1.2447 - val_accuracy: 0.2500\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2201 - accuracy: 0.1111 - val_loss: 1.2109 - val_accuracy: 0.1667\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.1952 - accuracy: 0.2130 - val_loss: 1.1822 - val_accuracy: 0.3333\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.1716 - accuracy: 0.2963 - val_loss: 1.1577 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.1489 - accuracy: 0.3241 - val_loss: 1.1341 - val_accuracy: 0.4167\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.1275 - accuracy: 0.3241 - val_loss: 1.1130 - val_accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.1076 - accuracy: 0.3519 - val_loss: 1.0932 - val_accuracy: 0.5000\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0882 - accuracy: 0.4352 - val_loss: 1.0741 - val_accuracy: 0.5000\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0695 - accuracy: 0.4722 - val_loss: 1.0555 - val_accuracy: 0.5833\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0522 - accuracy: 0.4630 - val_loss: 1.0383 - val_accuracy: 0.5000\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0349 - accuracy: 0.4444 - val_loss: 1.0213 - val_accuracy: 0.5000\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0180 - accuracy: 0.4630 - val_loss: 1.0052 - val_accuracy: 0.4167\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0025 - accuracy: 0.4722 - val_loss: 0.9906 - val_accuracy: 0.5833\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9866 - accuracy: 0.5000 - val_loss: 0.9757 - val_accuracy: 0.5833\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.9696 - accuracy: 0.5370 - val_loss: 0.9599 - val_accuracy: 0.5833\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9521 - accuracy: 0.5463 - val_loss: 0.9429 - val_accuracy: 0.5833\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9352 - accuracy: 0.5833 - val_loss: 0.9269 - val_accuracy: 0.6667\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9159 - accuracy: 0.6296 - val_loss: 0.9088 - val_accuracy: 0.6667\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8970 - accuracy: 0.6204 - val_loss: 0.8918 - val_accuracy: 0.6667\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8768 - accuracy: 0.6574 - val_loss: 0.8745 - val_accuracy: 0.5833\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8591 - accuracy: 0.6667 - val_loss: 0.8609 - val_accuracy: 0.5833\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8431 - accuracy: 0.6667 - val_loss: 0.8520 - val_accuracy: 0.5833\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8283 - accuracy: 0.6667 - val_loss: 0.8425 - val_accuracy: 0.5833\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8149 - accuracy: 0.6667 - val_loss: 0.8326 - val_accuracy: 0.5833\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8020 - accuracy: 0.6667 - val_loss: 0.8239 - val_accuracy: 0.5833\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7905 - accuracy: 0.6759 - val_loss: 0.8154 - val_accuracy: 0.5833\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7787 - accuracy: 0.6852 - val_loss: 0.8074 - val_accuracy: 0.8333\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7678 - accuracy: 0.7315 - val_loss: 0.7996 - val_accuracy: 0.9167\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7576 - accuracy: 0.7870 - val_loss: 0.7912 - val_accuracy: 0.9167\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7474 - accuracy: 0.8056 - val_loss: 0.7823 - val_accuracy: 0.9167\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7379 - accuracy: 0.8056 - val_loss: 0.7746 - val_accuracy: 0.9167\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7285 - accuracy: 0.8241 - val_loss: 0.7668 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7194 - accuracy: 0.8519 - val_loss: 0.7595 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7105 - accuracy: 0.8611 - val_loss: 0.7520 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7021 - accuracy: 0.8796 - val_loss: 0.7450 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6939 - accuracy: 0.8981 - val_loss: 0.7386 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6858 - accuracy: 0.9167 - val_loss: 0.7319 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6782 - accuracy: 0.9259 - val_loss: 0.7262 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6867 - accuracy: 0.8667\n",
      "Test Loss: 0.6867239475250244\n",
      "Test Accuracy: 0.8666666746139526\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "Predicted Classes: ['setosa', 'versicolor', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Create the MLP model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = [[5.1, 3.5, 1.4, 0.2], [6.4, 3.2, 4.5, 1.5], [7.3, 2.9, 6.3, 1.8]]\n",
    "\n",
    "\n",
    "predictions = model.predict(new_data)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_classes = [iris.target_names[pred.argmax()] for pred in predictions]\n",
    "print(\"Predicted Classes:\", predicted_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras with Support Vector Machine(SVM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 1.0\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3333 - accuracy: 0.3417\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.3333 - accuracy: 0.3000\n",
      "SVM-like model accuracy: 0.30000001192092896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the SVM model using SVC from scikit-learn\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "accuracy = svm_model.score(X_test, y_test)\n",
    "print(\"SVM accuracy:\", accuracy)\n",
    "\n",
    "# Alternatively, you can use Keras to build an SVM-like model\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=4, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='hinge', metrics=['accuracy'])\n",
    "\n",
    "# Train the SVM-like model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# Evaluate the SVM-like model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"SVM-like model accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras with reinforcement learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Discrete' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 42\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m q_table\n\u001b[0;32m     41\u001b[0m \u001b[39m# Train Q-learning agent\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m q_table \u001b[39m=\u001b[39m q_learning(env)\n\u001b[0;32m     44\u001b[0m \u001b[39mprint\u001b[39m(q_table)\n\u001b[0;32m     46\u001b[0m \u001b[39m# Test the agent\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m, in \u001b[0;36mq_learning\u001b[1;34m(env, episodes, alpha, gamma, epsilon)\u001b[0m\n\u001b[0;32m     11\u001b[0m n_actions \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39maction_space\n\u001b[0;32m     12\u001b[0m n_states \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mobservation_space\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> 13\u001b[0m q_table \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros((n_states, n_actions))\n\u001b[0;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m episode \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(episodes):\n\u001b[0;32m     17\u001b[0m     state \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Discrete' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Create the CartPole environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Q-learning algorithm\n",
    "def q_learning(env, episodes=1000, alpha=0.1, gamma=0.99, epsilon=0.1):\n",
    "    n_actions = env.action_space\n",
    "    n_states = env.observation_space.shape[0]\n",
    "    q_table = np.zeros((n_states, n_actions))\n",
    "    \n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            if float (np.random.rand()) < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q_table[state, :])\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            q_next = np.max(q_table[next_state, :])\n",
    "            q_table[state, action] = (1 - alpha) * q_table[state, action] + alpha * (reward + gamma * q_next)\n",
    "\n",
    "            state = next_state\n",
    "           \n",
    "\n",
    "    return q_table\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Train Q-learning agent\n",
    "q_table = q_learning(env)\n",
    "\n",
    "print(q_table)\n",
    "\n",
    "# Test the agent\n",
    "state = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = np.argmax(q_table[state, :])\n",
    "    next_state, _, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    state = next_state\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10204\\2262461823.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  action = np.argmax(q_table[state, :])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 37\u001b[0m\n\u001b[0;32m     33\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39mmake(\u001b[39m'\u001b[39m\u001b[39mAcrobot-v1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[39m# Train Q-learning agent\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m q_table \u001b[39m=\u001b[39m q_learning(env)\n\u001b[0;32m     39\u001b[0m \u001b[39mprint\u001b[39m(q_table)\n",
      "Cell \u001b[1;32mIn[11], line 17\u001b[0m, in \u001b[0;36mq_learning\u001b[1;34m(env, episodes, alpha, gamma, epsilon)\u001b[0m\n\u001b[0;32m     15\u001b[0m     action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(n_actions)\n\u001b[0;32m     16\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 17\u001b[0m     action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(q_table[state, :])\n\u001b[0;32m     19\u001b[0m next_state, reward, done, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[0;32m     21\u001b[0m q_value \u001b[39m=\u001b[39m q_table[state, action]\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "def q_learning(env, episodes=1000, alpha=0.1, gamma=0.99, epsilon=0.1):\n",
    "    n_actions = env.action_space.n\n",
    "    n_states = env.observation_space.shape[0]\n",
    "    q_table = np.zeros((n_states, n_actions))\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = np.random.choice(n_actions)\n",
    "            else:\n",
    "                action = np.argmax(q_table[state, :])\n",
    "            \n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            q_value = q_table[state, action]\n",
    "            next_q_max = np.max(q_table[next_state, :])\n",
    "            \n",
    "            new_q_value = (1 - alpha) * q_value + alpha * (reward + gamma * next_q_max)\n",
    "            q_table[state, action] = new_q_value\n",
    "            \n",
    "            state = next_state\n",
    "    \n",
    "    return q_table\n",
    "\n",
    "\n",
    "# Create the environment (replace 'CartPole-v1' with your desired environment)\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "\n",
    "# Train Q-learning agent\n",
    "q_table = q_learning(env)\n",
    "\n",
    "print(q_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "def q_learning(env, episodes=1000, alpha=0.1, gamma=0.99, epsilon=0.1):\n",
    "    n_actions = env.action_space.n\n",
    "    n_states = env.observation_space.shape[0]\n",
    "    q_table = np.zeros((n_states, n_actions))\n",
    "\n",
    "    # Rest of your Q-learning implementation here\n",
    "\n",
    "    return q_table\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# Train Q-learning agent for 1000 episodes (you can change this number as needed)\n",
    "q_table = q_learning(env, episodes=1000)\n",
    "\n",
    "print(q_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# N=np.random.rand()\n",
    "# N \n",
    "\n",
    "N=int(input(\"enter the number\"))\n",
    "\n",
    "print(n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "99/99 [==============================] - 1s 1ms/step - loss: 0.4214\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 0s 987us/step - loss: 0.2160\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 0s 997us/step - loss: 0.0636\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0276\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 0s 967us/step - loss: 0.0269\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 0s 967us/step - loss: 0.0269\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 0s 987us/step - loss: 0.0277\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 0s 977us/step - loss: 0.0270\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0271\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0267\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 0s 967us/step - loss: 0.0266\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 0s 967us/step - loss: 0.0269\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0265\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0265\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0269\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 0s 946us/step - loss: 0.0265\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0269\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 0s 987us/step - loss: 0.0267\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 0s 946us/step - loss: 0.0265\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 0s 997us/step - loss: 0.0267\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 0s 987us/step - loss: 0.0268\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 0s 997us/step - loss: 0.0267\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0269\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0268\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0273\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0269\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 0s 997us/step - loss: 0.0268\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0264\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0270\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0267\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0262\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0269\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0267\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0271\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0268\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0263\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0273\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0267\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0268\n",
      "Epoch 40/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0264\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0272\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0268\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0275\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0263\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 0s 967us/step - loss: 0.0272\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0268\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0268\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0267\n",
      "Epoch 49/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0268\n",
      "Epoch 50/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0269\n",
      "Epoch 51/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0265\n",
      "Epoch 52/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0268\n",
      "Epoch 53/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0271\n",
      "Epoch 54/100\n",
      "99/99 [==============================] - 0s 946us/step - loss: 0.0268\n",
      "Epoch 55/100\n",
      "99/99 [==============================] - 0s 946us/step - loss: 0.0267\n",
      "Epoch 56/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0267\n",
      "Epoch 57/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0266\n",
      "Epoch 58/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0264\n",
      "Epoch 59/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0270\n",
      "Epoch 60/100\n",
      "99/99 [==============================] - 0s 936us/step - loss: 0.0271\n",
      "Epoch 61/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0267\n",
      "Epoch 62/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0267\n",
      "Epoch 63/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0271\n",
      "Epoch 64/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0264\n",
      "Epoch 65/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0267\n",
      "Epoch 66/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0273\n",
      "Epoch 67/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0267\n",
      "Epoch 68/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0266\n",
      "Epoch 69/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0266\n",
      "Epoch 70/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0265\n",
      "Epoch 71/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0271\n",
      "Epoch 72/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0269\n",
      "Epoch 73/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0269\n",
      "Epoch 74/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0266\n",
      "Epoch 75/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0269\n",
      "Epoch 76/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0264\n",
      "Epoch 77/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0270\n",
      "Epoch 78/100\n",
      "99/99 [==============================] - 0s 946us/step - loss: 0.0269\n",
      "Epoch 79/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0266\n",
      "Epoch 80/100\n",
      "99/99 [==============================] - 0s 926us/step - loss: 0.0269\n",
      "Epoch 81/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0268\n",
      "Epoch 82/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0261\n",
      "Epoch 83/100\n",
      "99/99 [==============================] - 0s 946us/step - loss: 0.0273\n",
      "Epoch 84/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0267\n",
      "Epoch 85/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0267\n",
      "Epoch 86/100\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.0261\n",
      "Epoch 87/100\n",
      "99/99 [==============================] - 0s 987us/step - loss: 0.0272\n",
      "Epoch 88/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0264\n",
      "Epoch 89/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0264\n",
      "Epoch 90/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0265\n",
      "Epoch 91/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0267\n",
      "Epoch 92/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0266\n",
      "Epoch 93/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0267\n",
      "Epoch 94/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0267\n",
      "Epoch 95/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 0.0268\n",
      "Epoch 96/100\n",
      "99/99 [==============================] - 0s 936us/step - loss: 0.0268\n",
      "Epoch 97/100\n",
      "99/99 [==============================] - 0s 875us/step - loss: 0.0265\n",
      "Epoch 98/100\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.0269\n",
      "Epoch 99/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0264\n",
      "Epoch 100/100\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.0267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x277d2be6940>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Generate synthetic timeseries data\n",
    "def generate_timeseries_data(n_steps):\n",
    "    time = np.linspace(0, 2*np.pi, n_steps)\n",
    "    data = np.sin(time) + np.random.normal(0, 0.1, n_steps)\n",
    "    return data\n",
    "\n",
    "n_steps = 100\n",
    "data = generate_timeseries_data(n_steps)\n",
    "\n",
    "# Prepare data for LSTM (input and target)\n",
    "X = data[:-1]\n",
    "y = data[1:]\n",
    "\n",
    "# Reshape data for LSTM (samples, timesteps, features)\n",
    "X = X.reshape(-1, 1, 1)\n",
    "\n",
    "# Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(1, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, batch_size=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# Example categorical labels\n",
    "labels = ['cat', 'dog', 'bird', 'dog', 'cat']\n",
    "# Perform one-hot encoding\n",
    "encoded_labels = to_categorical(labels)\n",
    "print(encoded_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'dict' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'dict' and 'dict'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19176\\3275624622.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m# Train Q-learning agent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[0mq_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq_learning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;31m# Test the agent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19176\\3275624622.py\u001b[0m in \u001b[0;36mq_learning\u001b[1;34m(env, episodes, alpha, gamma, epsilon)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscretize_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Convert the state to a tuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19176\\3275624622.py\u001b[0m in \u001b[0;36mdiscretize_state\u001b[1;34m(state, n_buckets, state_bounds)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mn_bins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_buckets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mdiscretized_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlower_bound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupper_bound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_bins\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mdiscretized_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdigitize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscretized_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscretized_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mdigitize\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mdigitize\u001b[1;34m(x, bins, right)\u001b[0m\n\u001b[0;32m   5557\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mside\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mside\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5558\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5559\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mside\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mside\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36msearchsorted\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msearchsorted\u001b[1;34m(a, v, side, sorter)\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m     \"\"\"\n\u001b[1;32m-> 1387\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'searchsorted'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mside\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mside\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msorter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;31m# Call _wrapit from within the except clause to ensure a potential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;31m# exception has a traceback chain.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'dict' and 'dict'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Create the CartPole environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Function to discretize the continuous state space\n",
    "def discretize_state(state, n_buckets=(1, 1, 6, 12), state_bounds=None):\n",
    "    if state_bounds is None:\n",
    "        state_bounds = list(zip(env.observation_space.low, env.observation_space.high))\n",
    "        state_bounds[1] = [-0.5, 0.5]\n",
    "        state_bounds[3] = [-math.radians(50), math.radians(50)]\n",
    "\n",
    "    discretized_state = []\n",
    "    for i in range(len(state)):\n",
    "        value = state[i]\n",
    "        lower_bound, upper_bound = state_bounds[i]\n",
    "        n_bins = n_buckets[i]\n",
    "        discretized_value = np.linspace(lower_bound, upper_bound, n_bins + 1)[1:-1]\n",
    "        discretized_state.append(np.digitize(value, discretized_value))\n",
    "    return tuple(discretized_state)\n",
    "\n",
    "# Q-learning algorithm\n",
    "def q_learning(env, episodes=2000, alpha=0.1, gamma=0.99, epsilon=0.1):\n",
    "    n_actions = env.action_space.n\n",
    "    n_states = tuple((x + 1 for x in [1, 1, 6, 12]))  # Add 1 to each dimension to account for discretization\n",
    "\n",
    "    q_table = np.zeros(n_states + (n_actions,))\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        state = discretize_state(state)  # Convert the state to a tuple\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q_table[state])\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = discretize_state(next_state)\n",
    "\n",
    "            q_next = np.max(q_table[next_state])\n",
    "            q_table[state][action] = (1 - alpha) * q_table[state][action] + alpha * (reward + gamma * q_next)\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "    return q_table\n",
    "\n",
    "# Train Q-learning agent\n",
    "q_table = q_learning(env)\n",
    "\n",
    "# Test the agent\n",
    "state = env.reset()\n",
    "state = discretize_state(state)\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = np.argmax(q_table[state])\n",
    "    next_state, _, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    state = discretize_state(next_state)\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.src' has no attribute 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgym\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m Adam\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\__init__.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m __internal__\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m applications\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m callbacks\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\applications\\__init__.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m \u001b[39mimport\u001b[39;00m efficientnet_v2\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m \u001b[39mimport\u001b[39;00m imagenet_utils\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m \u001b[39mimport\u001b[39;00m inception_resnet_v2\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m \u001b[39mimport\u001b[39;00m inception_v3\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m \u001b[39mimport\u001b[39;00m mobilenet\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\applications\\inception_resnet_v2\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minception_resnet_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m InceptionResNetV2\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minception_resnet_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m decode_predictions\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minception_resnet_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m preprocess_input\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\applications\\__init__.py:41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mefficientnet_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m EfficientNetV2M\n\u001b[0;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mefficientnet_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m EfficientNetV2S\n\u001b[1;32m---> 41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minception_resnet_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m InceptionResNetV2\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minception_v3\u001b[39;00m \u001b[39mimport\u001b[39;00m InceptionV3\n\u001b[0;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmobilenet\u001b[39;00m \u001b[39mimport\u001b[39;00m MobileNet\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\applications\\inception_resnet_v2.py:324\u001b[0m\n\u001b[0;32m    320\u001b[0m         x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mActivation(activation, name\u001b[39m=\u001b[39mac_name)(x)\n\u001b[0;32m    321\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m--> 324\u001b[0m \u001b[39m@keras\u001b[39m\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39mregister_keras_serializable()\n\u001b[0;32m    325\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCustomScaleLayer\u001b[39;00m(keras_layers\u001b[39m.\u001b[39mLayer):\n\u001b[0;32m    326\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, scale, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    327\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.src' has no attribute 'utils'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from collections import deque\n",
    "import random\n",
    "# from keras import utils\n",
    "# from keras import utils\n",
    "\n",
    "\n",
    "\n",
    "# Create the CartPole environmen\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "# Define the DQN model\n",
    "model = Sequential([\n",
    "    Dense(24, input_dim=state_size, activation='relu'),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(action_size, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(lr=0.001))\n",
    "\n",
    "# Initialize replay memory\n",
    "memory = deque(maxlen=2000)\n",
    "# Hyperparameters\n",
    "gamma, epsilon, epsilon_min, epsilon_decay = 0.95, 1.0, 0.01, 0.995\n",
    "batch_size, n_episodes = 32, 10\n",
    "# Main training loop\n",
    "for episode in range(n_episodes):\n",
    "    state, total_reward = env.reset(), 0\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "\n",
    "    for time in range(500):\n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = np.argmax(model.predict(state)[0])\n",
    "\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        total_reward += reward\n",
    "\n",
    "        memory.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            print(f\"Episode: {episode + 1}, Score: {time + 1}, Epsilon: {epsilon:.2f}\")\n",
    "            break\n",
    "            \n",
    "        if len(memory) > batch_size:\n",
    "            minibatch = random.sample(memory, batch_size)\n",
    "            for state, action, reward, next_state, done in minibatch:\n",
    "                target = reward + gamma * np.amax(model.predict(next_state)[0])\n",
    "                target_f = model.predict(state)\n",
    "                target_f[0][action] = target\n",
    "                model.fit(state, target_f, epochs=1, verbose=0)\n",
    "    epsilon = max(epsilon * epsilon_decay, epsilon_min)\n",
    "\n",
    "env.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
